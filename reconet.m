function [Y,Xf,Af] = reconet(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 16-Dec-2015 11:48:11.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timsteps
%   Each X{1,ts} = 9xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 6xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [0.381294964028777;0;2.82842712474619;2.82842712474619;0;225;224;224;0];
x1_step1_gain = [0.877546158427635;0.0174262578018871;0.0188154974874582;0.0193710195613937;0.0161321801029225;0.166666666666667;0.181818181818182;0.166666666666667;2];
x1_step1_ymin = -1;

% Layer 1
b1 = [-2.0594171404058943;0.21069699080683804;1.4748526268203774;1.770045826664328;2.2590718889407584];
IW1_1 = [0.10674751309209503 -0.37551031123122169 0.86284270509373073 0.17880263907821822 1.0923607800724433 0.28384092972202574 -0.60115133838362211 -0.54232323786233239 -2.1917746551003723;0.77417998863462301 2.1258946131521914 3.0427473540507686 1.155717911779498 1.060241964823728 -4.5246376943336246 1.2473818614539895 0.7696326126156301 -0.6686685200582061;-1.1780936652043612 -1.5560896874166998 -3.1394770913844225 3.1784350309927278 3.05599212577195 5.7568309912564652 -5.3812511866361419 1.3614681246962499 -1.0061332581699074;1.1461415331173332 -0.36688464772564661 -5.3067922865348871 -2.135093724090344 -1.1808453942886894 -0.76377277965151003 -3.6134247617690587 -2.8564191334080644 4.2653310607312953;-3.3877499114284388 1.2341441153101542 4.449296970125256 0.84731978627599591 1.0214626119676666 -1.3070549005163332 -0.3187772313862533 -1.5562424954662506 5.031956213567673];

% Layer 2
b2 = [-4.8525556045131033;2.8936812250411985;-1.9787546352342638;0.56339509963811651;0.36686386195538573;3.2720047495129623];
LW2_1 = [2.9421835387782251 -2.8021409351618662 11.622407942131991 7.8460790490881189 4.7821091062498509;-3.0500330652093703 -1.4954320997261357 -14.711684265276801 -7.2434676436411705 -7.727173115490408;2.8594856627794067 -4.8494828140651363 -6.6899309806251255 6.39570568115243 5.8420396131818455;-3.7434944018350116 9.2263143053944425 0.092574457135302685 5.8098105553676715 1.7281747219914037;3.2465038026198481 5.9866343740554644 3.5661466664440447 -4.8818888559137381 0.74816960890301254;-4.1006525068079389 -6.1620149180093406 6.7968164336567272 -6.1478847702726647 -7.0223658364922716];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numer = exp(n);
denom = sum(numer,1);
denom(denom == 0) = 1;
a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
